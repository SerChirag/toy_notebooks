{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive IMLE vs Vanilla IMLE\n",
    "In this notebook, we showcase a very basic implementation for [Adaptive IMLE](paper_link) and [Vanilla IMLE](https://arxiv.org/abs/1809.09087) in 2D.\n",
    "\n",
    "While Vanilla IMLE fails to cover all data examples even in this simple situation, Adaptive IMLE covers all data examples showing superior mode-coverage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from siren_pytorch import SirenNet\n",
    "from prdc import compute_prdc\n",
    "\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "Here we define a simple generator consisting of a few fully connected layers. We initial its weight using standard Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    def truncated_normal_init(t, mean=0.0, std=0.5):\n",
    "        torch.nn.init.normal_(t, mean=mean, std=std)\n",
    "        while True:\n",
    "            cond = torch.logical_or(t < mean - 2 * std, t > mean + 2 * std)\n",
    "            if not torch.sum(cond):\n",
    "                break\n",
    "            t = torch.where(cond, torch.nn.init.normal_(torch.ones(t.shape), mean=mean, std=std), t)\n",
    "        return t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_mlp=5, in_dim=32, out_dim=2, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        assert(n_mlp >= 2)\n",
    "\n",
    "        layers = [nn.Linear(in_dim, hidden_dim), nn.LeakyReLU(0.2)]\n",
    "        for i in range(n_mlp - 2):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.Sigmoid())\n",
    "        layers.append(nn.Linear(hidden_dim, out_dim))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "#         self.apply(init_weights)        \n",
    "\n",
    "\n",
    "    def forward(self, latents):\n",
    "        return self.layers(latents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting function\n",
    "We define a simple plotting function to visualize data examples and generated examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde(generated, data_points, f_name, title):\n",
    "    plt.clf()\n",
    "    data = pd.DataFrame.from_dict({'x': generated[:, 0], 'y': generated[:, 1]})\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.ylim(-0.3, 0.4)\n",
    "    plt.xlim(-0.35, 0.35)\n",
    "    plt.title(title)\n",
    "    plt.scatter(data_points[:, 0], data_points[:, 1], label=\"Real data points\", color=\"blue\")\n",
    "    sns.kdeplot(data=data, fill=True, levels=200, alpha=0.5, palette=\"rocket_r\") \n",
    "    plt.savefig(f_name)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "\n",
    "def plot_nns(g, data_points, zs, selected_z, title=None, f_name=None, arrow=False, vanilla=False):\n",
    "    generated = g(zs).detach()\n",
    "    if(not vanilla):\n",
    "        selected = g(selected_z).detach()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "    plt.scatter(data_points[:, 0], data_points[:, 1], label=\"Real data points\", color=\"blue\", marker=\"s\")\n",
    "    plt.scatter(generated[:, 0], generated[:, 1], label=\"Generated samples\", color=\"orange\", alpha=0.4, marker=\".\")\n",
    "    if(not vanilla):\n",
    "        plt.scatter(selected[:, 0], selected[:, 1], label=\"Nearest neighbours\", color=\"red\",marker=\".\")\n",
    "\n",
    "    if arrow:\n",
    "        gen_to_data_vec = data_points - generated\n",
    "        # unit_vecs = gen_to_data_vec / np.linalg.norm(gen_to_data_vec, axis=1)[:, None]\n",
    "        plt.quiver(generated[:, 0], generated[:, 1], 0.19*gen_to_data_vec[:, 0], 0.19*gen_to_data_vec[:, 1],\n",
    "                   color=\"black\", scale_units=\"xy\", angles='xy', scale=0.2, width=0.0015, headwidth=10, headlength=10, label=\"Nearest neighbour vectors\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.ylim(-1.2, 1.2)\n",
    "    plt.xlim(-1.2, 1.2)\n",
    "    if f_name:\n",
    "        plt.savefig(f_name)\n",
    "        plt.close()\n",
    "        #plot_kde(generated, data_points, f_name.replace(\".png\", \"_kde.png\"), title)\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "def plot_final(g, data_points, zs, selected_z, title=None, f_name=None, arrow=False, vanilla=False):\n",
    "    generated = g(zs).detach()\n",
    "    if(not vanilla):\n",
    "        selected = g(selected_z).detach()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "    # plt.scatter(data_points[:, 0], data_points[:, 1], label=\"Real data points\", color=\"blue\", marker=\"s\")\n",
    "    plt.scatter(generated[:, 0], generated[:, 1], label=\"Generated samples\", color=\"orange\", alpha=0.1, marker=\".\")\n",
    "    if(not vanilla):\n",
    "        plt.scatter(selected[:, 0], selected[:, 1], label=\"Nearest neighbours\", color=\"red\",marker=\".\")\n",
    "\n",
    "    if arrow:\n",
    "        gen_to_data_vec = data_points - generated\n",
    "        # unit_vecs = gen_to_data_vec / np.linalg.norm(gen_to_data_vec, axis=1)[:, None]\n",
    "        plt.quiver(generated[:, 0], generated[:, 1], 0.19*gen_to_data_vec[:, 0], 0.19*gen_to_data_vec[:, 1],\n",
    "                   color=\"black\", scale_units=\"xy\", angles='xy', scale=0.2, width=0.0015, headwidth=10, headlength=10, label=\"Nearest neighbour vectors\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.ylim(-1.2, 1.2)\n",
    "    plt.xlim(-1.2, 1.2)\n",
    "    if f_name:\n",
    "        plt.savefig(f_name)\n",
    "        plt.close()\n",
    "        #plot_kde(generated, data_points, f_name.replace(\".png\", \"_kde.png\"), title)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Here we defined a few hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdim = 32  # latent space dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Here we consider some 2D data examples defined by _data\\_points_. We create a generator object and visualize some generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Generator(n_mlp=3, in_dim=zdim, hidden_dim=32, out_dim=20)\n",
    "# g = GeneratorLehsun(n_mlp=4, in_dim=zdim)\n",
    "# data_points = torch.tensor([\n",
    "#         [-0.1257,  0.3797],\n",
    "#         [-0.1573,  0.1287],\n",
    "#         [ 0.1076,  0.0971],\n",
    "#         [ 0.1443,  0.1333],\n",
    "#         [-0.1243,  0.1533],\n",
    "#         [-0.0321,  0.1898],\n",
    "#         [ 0.1347, -0.1573],\n",
    "#         [-0.3069,  0.2949],\n",
    "#         [ 0.0202,  0.1158],\n",
    "#         [ 0.3023,  0.3158],\n",
    "#         [ 0.2379, -0.2279],\n",
    "#         [-0.2379, -0.2279],\n",
    "#         [-0.0295,  0.0197],\n",
    "#         [ 0.0853, -0.0708]])\n",
    "\n",
    "data_points = torch.load(\"random.pt\").long()\n",
    "\n",
    "n = data_points.shape[0]\n",
    "nz = data_points.shape[0]*10  # pool size\n",
    "zs = torch.randn(nz, zdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001  # learning rate\n",
    "epochs = 10000  # number of epochs for training\n",
    "tau=0.95  # tightening threshold defined in the Adaptive IMLE paper\n",
    "noise_coef = 0.000001  # additive noise coeficient\n",
    "staleness = 1000  # staleness for Vanilla IMLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbours\n",
    "Here we define a naive function to find nearest neighbour of each data example. This nearest neighbour part can be vastly optimized using [DCI](https://arxiv.org/abs/1703.00440)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nn(data_point, generated):\n",
    "    dists = torch.sum((generated - data_point)**2, dim=1)\n",
    "    dists = dists**0.5\n",
    "    return torch.argmin(dists).item()\n",
    "\n",
    "def find_nn_new(data_point, generated, limit = 1e-3):\n",
    "    dists = torch.sum((generated - data_point)**2, dim=1)\n",
    "    dists = dists**0.5\n",
    "    to_update = dists < limit\n",
    "    dists[to_update] = np.inf\n",
    "    return torch.argmin(dists).item()\n",
    "\n",
    "def find_nn_k(data_point, generated, k = 3):\n",
    "    dists = torch.sum((generated - data_point)**2, dim=1)\n",
    "    dists = dists**0.5\n",
    "    least_k = torch.topk(dists, k, sorted=True, largest=False)\n",
    "    return least_k.indices[k-1]\n",
    "\n",
    "generated = g(zs).detach()\n",
    "nns = [find_nn(data_points[i], generated) for i in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive IMLE implementation\n",
    "Here we implement a basic version of Adaptive IMLE.\n",
    "The original implementation makes use of several other parts that helps with much faster nearest neighbour search, better convergence and faster training. Here we omit these parts just to show case the algorithm and its simplicity.\n",
    "\n",
    "For the original impelementation refer to the [github repo]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100000/100000 [02:02<00:00, 817.41it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "nz = data_points.shape[0]*10\n",
    "ada_imle_g = copy.deepcopy(g)\n",
    "optim = torch.optim.Adam(ada_imle_g.parameters(), lr=lr)\n",
    "staleness = 5000\n",
    "ada_imle_nn_z = torch.randn(n, zdim)\n",
    "# ada_imle_nn_z = nn.functional.normalize(ada_imle_nn_z, dim=1)\n",
    "\n",
    "dists = torch.tensor([0.1] * n)\n",
    "prev = dists[:]\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    with torch.no_grad():\n",
    "        dists = torch.sum((ada_imle_g(ada_imle_nn_z) - data_points)**2, dim=1)\n",
    "        to_update = dists < prev * tau \n",
    "\n",
    "        zs = torch.randn(nz, zdim)\n",
    "#         zs = nn.functional.normalize(zs, dim=1)\n",
    "\n",
    "        generated = ada_imle_g(zs).detach()\n",
    "        nns = torch.tensor([find_nn(d, generated) for d in data_points[to_update]], dtype=torch.long)\n",
    "        ada_imle_nn_z[to_update] = zs[nns] + torch.randn(nns.shape[0], zdim) * noise_coef\n",
    "\n",
    "        generated = ada_imle_g(ada_imle_nn_z)\n",
    "        dists = torch.sum((generated - data_points)**2, dim=1)\n",
    "        prev[to_update] = dists[to_update] * tau\n",
    "        # save data as tensor\n",
    "        \n",
    "#         if e % staleness == 0:\n",
    "#             nz_fake = data_points.shape[0]*10\n",
    "#             zs_fake = torch.randn(nz_fake, zdim)\n",
    "# #             zs_fake = nn.functional.normalize(zs_fake, dim=1)\n",
    "# #             zs_fake *= zdim**0.5\n",
    "#             plot_nns(ada_imle_g, data_points, zs_fake, ada_imle_nn_z, title=f\"Epoch {e}\", f_name=f\"plots_soviet/ada-epoch-{e}-{nz}.png\", arrow=False)\n",
    "\n",
    "#     ada_imle_nn_z = nn.functional.normalize(ada_imle_nn_z, dim=1)\n",
    "    optim.zero_grad()\n",
    "#     ada_imle_nn_z *= zdim**0.5\n",
    "    outs = ada_imle_g(ada_imle_nn_z)\n",
    "    dists = torch.sum((outs - data_points)**2, dim=0)\n",
    "\n",
    "    loss = dists.mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "#Saving the training visualizations as GIF\n",
    "# with imageio.get_writer(f'plots_soviet/adaptive_imle_training-{nz}.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,staleness):\n",
    "#         filename = f\"plots_soviet/ada-epoch-{e}-{nz}.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         #os.remove(filename)\n",
    "\n",
    "# with imageio.get_writer(f'adaptive_imle_training_kde.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,staleness):\n",
    "#         filename = f\"plots/ada-epoch-{e}_kde.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         os.remove(filename)\n",
    "\n",
    "# nz_fake = data_points.shape[0]*10\n",
    "# zs_fake = torch.randn(nz_fake, zdim)\n",
    "# # zs_fake = nn.functional.normalize(zs_fake, dim=1)\n",
    "# # zs_fake *= zdim**0.5\n",
    "# plot_final(ada_imle_g, data_points, zs_fake, None, title=\"AdaIMLE\", f_name=f\"plots_soviet/ada-final-{nz}.png\", arrow=False, vanilla=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'epoch': e,\n",
    "#             'model_state_dict': ada_imle_g.state_dict(),\n",
    "#             'optimizer_state_dict': optim.state_dict()}, \n",
    "#            \"./plot_random/ada_imle.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num real: 150 Num fake: 150\n",
      "{'precision': 0.5333333333333333, 'recall': 0.9533333333333334, 'density': 0.6493333333333333, 'coverage': 0.8866666666666667}\n"
     ]
    }
   ],
   "source": [
    "nz_fake = data_points.shape[0]*1\n",
    "zs_fake = torch.randn(nz_fake, zdim)\n",
    "fake = ada_imle_g(zs_fake).cpu().detach().numpy()\n",
    "metrics = compute_prdc(real_features=data_points,\n",
    "                       fake_features=fake,\n",
    "                       nearest_k=5)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMLE with splatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100000/100000 [02:13<00:00, 750.17it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "nz = data_points.shape[0]*10\n",
    "splatter_imle_g = copy.deepcopy(g)\n",
    "optim = torch.optim.Adam(splatter_imle_g.parameters(), lr=lr)\n",
    "staleness = 5000\n",
    "ada_imle_nn_z = torch.randn(n, zdim)\n",
    "# ada_imle_nn_z = nn.functional.normalize(ada_imle_nn_z, dim=1)\n",
    "\n",
    "dists = torch.tensor([0.1] * n)\n",
    "prev = dists[:]\n",
    "angle = 10.0\n",
    "angle_distort = torch.deg2rad(torch.tensor(angle))\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    with torch.no_grad():\n",
    "        dists = torch.sum((splatter_imle_g(ada_imle_nn_z) - data_points)**2, dim=1)\n",
    "        to_update = dists < prev * tau \n",
    "\n",
    "        zs = torch.randn(nz, zdim)\n",
    "#         zs = nn.functional.normalize(zs, dim=1)\n",
    "\n",
    "        generated = splatter_imle_g(zs).detach()\n",
    "        nns = torch.tensor([find_nn(d, generated) for d in data_points[to_update]], dtype=torch.long)\n",
    "        ada_imle_nn_z[to_update] = zs[nns] + torch.randn(nns.shape[0], zdim) * noise_coef\n",
    "\n",
    "        generated = splatter_imle_g(ada_imle_nn_z)\n",
    "        dists = torch.sum((generated - data_points)**2, dim=1)\n",
    "        prev[to_update] = dists[to_update] * tau\n",
    "        # save data as tensor\n",
    "        \n",
    "#         if e % staleness == 0:\n",
    "#             nz_fake = data_points.shape[0]*10\n",
    "#             zs_fake = torch.randn(nz_fake, zdim)\n",
    "# #             zs_fake = nn.functional.normalize(zs_fake, dim=1)\n",
    "#             plot_nns(splatter_imle_g, data_points, zs_fake, ada_imle_nn_z, title=f\"Epoch {e}\", f_name=f\"plots_soviet/splatter-epoch-{e}-{nz}-{angle}.png\", arrow=False)\n",
    "\n",
    "\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    norms = torch.norm(ada_imle_nn_z,dim=1,p=2)\n",
    "    norm_ada_imle_nn_z = nn.functional.normalize(ada_imle_nn_z, dim=1, p=2)\n",
    "      \n",
    "    b = torch.normal(0,1,size=norm_ada_imle_nn_z.shape)\n",
    "    b = nn.functional.normalize(b, dim=1)\n",
    "\n",
    "    w = b - torch.unsqueeze(torch.einsum('ij,ij->i',b,norm_ada_imle_nn_z),-1) * norm_ada_imle_nn_z\n",
    "    w = nn.functional.normalize(w,p=2,dim=-1)\n",
    "\n",
    "    cur_batch_latents = torch.cos(angle_distort) * norm_ada_imle_nn_z + torch.sin(angle_distort) * w\n",
    "    \n",
    "#     print(torch.norm(cur_batch_latents,dim=1))\n",
    "#     print(norms.shape)\n",
    "    cur_batch_latents = cur_batch_latents * norms.view(-1, 1)\n",
    "    \n",
    "    outs = splatter_imle_g(cur_batch_latents)\n",
    "    dists = torch.sum((outs - data_points)**2, dim=0)\n",
    "\n",
    "    loss = dists.mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "# #Saving the training visualizations as GIF\n",
    "# with imageio.get_writer(f'plots_soviet/splatter_imle_training-{nz}-{angle}.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,staleness):\n",
    "#         filename = f\"plots_soviet/splatter-epoch-{e}-{nz}-{angle}.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         #os.remove(filename)\n",
    "\n",
    "# # with imageio.get_writer(f'adaptive_imle_training_kde.gif', mode='I') as writer:\n",
    "# #     for e in range(0,epochs,staleness):\n",
    "# #         filename = f\"plots/ada-epoch-{e}_kde.png\"\n",
    "# #         image = imageio.imread(filename)\n",
    "# #         writer.append_data(image)\n",
    "# #         os.remove(filename)\n",
    "\n",
    "# nz_fake = data_points.shape[0]*10\n",
    "# zs_fake = torch.randn(nz_fake, zdim)\n",
    "# # zs_fake = nn.functional.normalize(zs_fake, dim=1)\n",
    "# plot_final(splatter_imle_g, data_points, zs_fake, None, title=\"AdaIMLE\", f_name=f\"plots_soviet/splatter-final-{nz}-{angle}.png\", arrow=False, vanilla=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num real: 150 Num fake: 150\n",
      "{'precision': 1.0, 'recall': 0.9933333333333333, 'density': 1.2821333333333333, 'coverage': 1.0}\n"
     ]
    }
   ],
   "source": [
    "nz_fake = data_points.shape[0]*1\n",
    "zs_fake = torch.randn(nz_fake, zdim)\n",
    "fake = splatter_imle_g(zs_fake).cpu().detach().numpy()\n",
    "metrics = compute_prdc(real_features=data_points,\n",
    "                       fake_features=fake,\n",
    "                       nearest_k=50)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'epoch': e,\n",
    "            'model_state_dict': splatter_imle_g.state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict()}, \n",
    "           f\"./plot_random/ada_imle-{angle_distort}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nz_fake = data_points.shape[0]*10\n",
    "# zs_fake = torch.randn(nz_fake, zdim)\n",
    "# plot_final(splatter_imle_g, data_points, zs_fake, None, title=\"AdaIMLE\", f_name=f\"plots_soviet/splatter-final-{nz}.png\", arrow=False, vanilla=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████████▉                                                                                                                           | 1767/20000 [00:05<00:57, 317.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m to_update \u001b[38;5;241m=\u001b[39m dists \u001b[38;5;241m<\u001b[39m prev \u001b[38;5;241m*\u001b[39m tau \n\u001b[1;32m     16\u001b[0m zs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(nz, zdim)\n\u001b[0;32m---> 17\u001b[0m generated \u001b[38;5;241m=\u001b[39m \u001b[43mada_imle_g_knn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     18\u001b[0m nns \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([find_nn_k(d, generated, k\u001b[38;5;241m=\u001b[39mknn) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data_points[to_update]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     19\u001b[0m ada_imle_nn_z[to_update] \u001b[38;5;241m=\u001b[39m zs[nns] \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(nns\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], zdim) \u001b[38;5;241m*\u001b[39m noise_coef\n",
      "File \u001b[0;32m~/anaconda3/envs/pypi/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, latents)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, latents):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pypi/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/pypi/lib/python3.8/site-packages/torch/nn/modules/container.py:119\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20000\n",
    "nz = data_points.shape[0]*5\n",
    "ada_imle_g_knn = copy.deepcopy(g)\n",
    "optim = torch.optim.Adam(ada_imle_g_knn.parameters(), lr=lr)\n",
    "\n",
    "ada_imle_nn_z = torch.randn(n, zdim)\n",
    "dists = torch.tensor([0.1] * n)\n",
    "prev = dists[:]\n",
    "knn = 15\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    with torch.no_grad():\n",
    "        dists = torch.sum((ada_imle_g_knn(ada_imle_nn_z) - data_points)**2, dim=1)\n",
    "        to_update = dists < prev * tau \n",
    "\n",
    "        zs = torch.randn(nz, zdim)\n",
    "        generated = ada_imle_g_knn(zs).detach()\n",
    "        nns = torch.tensor([find_nn_k(d, generated, k=knn) for d in data_points[to_update]], dtype=torch.long)\n",
    "        ada_imle_nn_z[to_update] = zs[nns] + torch.randn(nns.shape[0], zdim) * noise_coef\n",
    "\n",
    "        generated = ada_imle_g_knn(ada_imle_nn_z)\n",
    "        dists = torch.sum((generated - data_points)**2, dim=1)\n",
    "        prev[to_update] = dists[to_update] * tau\n",
    "        # save data as tensor\n",
    "        torch.save(ada_imle_nn_z, f\"data/z-epoch-{e}.pt\")\n",
    "        torch.save(ada_imle_g_knn, f\"data/g-epoch-{e}.pt\")\n",
    "        torch.save(data_points, f\"data/data_points.pt\")\n",
    "        torch.save(prev, f\"data/prev-epoch-{e}.pt\")\n",
    "        if e % staleness == 0:\n",
    "            nz_fake = data_points.shape[0]*10\n",
    "            zs_fake = torch.randn(nz_fake, zdim)\n",
    "            plot_nns(ada_imle_g_knn, data_points, zs_fake, ada_imle_nn_z, title=f\"Epoch {e}\", f_name=f\"plots_soviet/ada-epoch-{knn}-knn-{e}-{nz}.png\", arrow=False)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    outs = ada_imle_g_knn(ada_imle_nn_z)\n",
    "    dists = torch.sum((outs - data_points)**2, dim=0)\n",
    "\n",
    "    loss = dists.mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "#Saving the training visualizations as GIF\n",
    "with imageio.get_writer(f'plots_soviet/adaptive_imle_{knn}_knn_training-{nz}.gif', mode='I') as writer:\n",
    "    for e in range(0,epochs,staleness):\n",
    "        filename = f\"plots_soviet/ada-epoch-{knn}-knn-{e}-{nz}.png\"\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "nz_fake = data_points.shape[0]*10\n",
    "zs_fake = torch.randn(nz_fake, zdim)\n",
    "plot_final(ada_imle_g_knn, data_points, zs_fake, None, title=\"AdaIMLE\", f_name=f\"plots_soviet/ada-knn-{knn}-final-{nz}.png\", arrow=False, vanilla=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [02:57<00:00, 281.79it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50000\n",
    "ada_imle_g = copy.deepcopy(g)\n",
    "optim = torch.optim.Adam(ada_imle_g.parameters(), lr=lr)\n",
    "plot_staleness = 5000\n",
    "\n",
    "ada_imle_nn_z = torch.randn(n, zdim)\n",
    "dists = torch.tensor([0.1] * n)\n",
    "prev = dists[:]\n",
    "limit_threshold = 1e-2\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    with torch.no_grad():\n",
    "        dists = torch.sum((ada_imle_g(ada_imle_nn_z) - data_points)**2, dim=1)\n",
    "        to_update = dists < prev * tau \n",
    "\n",
    "        zs = torch.randn(nz, zdim)\n",
    "        generated = ada_imle_g(zs).detach()\n",
    "        nns = torch.tensor([find_nn_new(d, generated, limit=limit_threshold) for d in data_points[to_update]], dtype=torch.long)\n",
    "        ada_imle_nn_z[to_update] = zs[nns] + torch.randn(nns.shape[0], zdim) * noise_coef\n",
    "\n",
    "        generated = ada_imle_g(ada_imle_nn_z)\n",
    "        dists = torch.sum((generated - data_points)**2, dim=1)\n",
    "        prev[to_update] = dists[to_update] * tau\n",
    "        # save data as tensor\n",
    "        if e % plot_staleness == 0:\n",
    "            plot_nns(ada_imle_g, data_points, zs, ada_imle_nn_z, title=f\"Epoch {e}\", f_name=f\"plots_soviet/ada-limit-epoch-{e}.png\", arrow=False)\n",
    "\n",
    "\n",
    "    optim.zero_grad()\n",
    "    outs = ada_imle_g(ada_imle_nn_z)\n",
    "    dists = torch.sum((outs - data_points)**2, dim=0)\n",
    "\n",
    "    loss = dists.mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "#Saving the training visualizations as GIF\n",
    "with imageio.get_writer(f'plots_soviet/adaptive_imle_limit_training.gif', mode='I') as writer:\n",
    "    for e in range(0,epochs,plot_staleness):\n",
    "        filename = f\"plots_soviet/ada-limit-epoch-{e}.png\"\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        #os.remove(filename)\n",
    "\n",
    "# with imageio.get_writer(f'adaptive_imle_training_kde.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,staleness):\n",
    "#         filename = f\"plots/ada-epoch-{e}_kde.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         os.remove(filename)\n",
    "\n",
    "zs = torch.randn(nz, zdim)\n",
    "plot_final(ada_imle_g, data_points, zs, None, title=\"Ada-IMLE new distance\", f_name=f\"plots_soviet/ada-limit-final.png\", arrow=False, vanilla=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nn_improved(data_point, generated, limit = 1e-3,print_results=False):\n",
    "    l2_distances = np.linalg.norm(generated[:, np.newaxis] - data_point , axis=2)\n",
    "    to_exclude = l2_distances < limit\n",
    "    bad_samples_list = np.expand_dims(to_exclude.any(axis=1),-1)\n",
    "    bad_samples_list_repeated = np.tile(bad_samples_list,to_exclude.shape[1])\n",
    "    l2_distances[bad_samples_list_repeated] = np.inf\n",
    "    result = np.argmin(l2_distances,axis=0)\n",
    "    return result\n",
    "\n",
    "def find_nn_new_multi(data_point, generated, limit = 1e-3):\n",
    "    l2_distances = np.linalg.norm(generated[:, np.newaxis] - data_point , axis=2)\n",
    "    to_exclude = l2_distances < limit\n",
    "    l2_distances[to_exclude] = np.inf\n",
    "    result = np.argmin(l2_distances,axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved + splatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [01:15<00:00, 665.08it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50000\n",
    "ada_imle_g = copy.deepcopy(g)\n",
    "optim = torch.optim.Adam(ada_imle_g.parameters(), lr=lr)\n",
    "plot_staleness = 5000\n",
    "\n",
    "angle = 5.0\n",
    "angle_distort = torch.deg2rad(torch.tensor(angle))\n",
    "\n",
    "ada_imle_nn_z = torch.randn(n, zdim)\n",
    "\n",
    "dists = torch.tensor([0.1] * n)\n",
    "prev = dists[:]\n",
    "distance_threshold = 5e-3\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    with torch.no_grad():\n",
    "#         if(e % 10000 == 0 and e > 0 and distance_threshold < 6e-3):\n",
    "#             distance_threshold += 1e-3\n",
    "#             print(\"Distance threshold is: \",distance_threshold)\n",
    "        dists = torch.sum((ada_imle_g(ada_imle_nn_z) - data_points)**2, dim=1)\n",
    "        to_update = dists < prev * tau \n",
    "\n",
    "        zs = torch.randn(nz, zdim)\n",
    "\n",
    "        generated = ada_imle_g(zs).detach()\n",
    "        nns = torch.tensor(find_nn_improved(data_points[to_update], generated, limit=distance_threshold, print_results=True), dtype=torch.long)\n",
    "        ada_imle_nn_z[to_update] = zs[nns] + torch.randn(nns.shape[0], zdim) * noise_coef\n",
    "\n",
    "        generated = ada_imle_g(ada_imle_nn_z)\n",
    "        dists = torch.sum((generated - data_points)**2, dim=1)\n",
    "        prev[to_update] = dists[to_update] * tau\n",
    "        # save data as tensor\n",
    "    \n",
    "    norms = torch.norm(ada_imle_nn_z,dim=1,p=2)\n",
    "    norm_ada_imle_nn_z = nn.functional.normalize(ada_imle_nn_z, dim=1, p=2)\n",
    "    \n",
    "    b = torch.normal(0,1,size=norm_ada_imle_nn_z.shape)\n",
    "    b = nn.functional.normalize(b, dim=1)\n",
    "\n",
    "    w = b - torch.unsqueeze(torch.einsum('ij,ij->i',b,norm_ada_imle_nn_z),-1) * norm_ada_imle_nn_z\n",
    "    w = nn.functional.normalize(w,p=2,dim=-1)\n",
    "\n",
    "    cur_batch_latents = torch.cos(angle_distort) * norm_ada_imle_nn_z + torch.sin(angle_distort) * w\n",
    "    cur_batch_latents = cur_batch_latents * norms.view(-1, 1)\n",
    "   \n",
    "    optim.zero_grad()\n",
    "    outs = ada_imle_g(cur_batch_latents)\n",
    "    dists = torch.sum((outs - data_points)**2, dim=0)\n",
    "\n",
    "    loss = dists.mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "#Saving the training visualizations as GIF\n",
    "# with imageio.get_writer(f'plots_soviet/splatter_imle_improved_training.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,plot_staleness):\n",
    "#         filename = f\"plots_soviet/ada-splatter-improved-epoch-{e}.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         #os.remove(filename)\n",
    "\n",
    "# # with imageio.get_writer(f'adaptive_imle_training_kde.gif', mode='I') as writer:\n",
    "# #     for e in range(0,epochs,staleness):\n",
    "# #         filename = f\"plots/ada-epoch-{e}_kde.png\"\n",
    "# #         image = imageio.imread(filename)\n",
    "# #         writer.append_data(image)\n",
    "# #         os.remove(filename)\n",
    "\n",
    "# zs = torch.randn(nz, zdim)\n",
    "# plot_final(ada_imle_g, data_points, zs, None, title=\"Ada-IMLE new distance\", f_name=f\"plots_soviet/ada-splatter-improved-final.png\", arrow=False, vanilla=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num real: 150 Num fake: 150\n",
      "{'precision': 1.0, 'recall': 0.0, 'density': 10.893333333333334, 'coverage': 0.4866666666666667}\n"
     ]
    }
   ],
   "source": [
    "nz_fake = data_points.shape[0]*1\n",
    "zs_fake = torch.randn(nz_fake, zdim)\n",
    "fake = ada_imle_g(zs_fake).cpu().detach().numpy()\n",
    "metrics = compute_prdc(real_features=data_points,\n",
    "                       fake_features=fake,\n",
    "                       nearest_k=5)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100000/100000 [02:13<00:00, 749.61it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "ada_imle_g = copy.deepcopy(g)\n",
    "optim = torch.optim.Adam(ada_imle_g.parameters(), lr=lr)\n",
    "plot_staleness = 5000\n",
    "\n",
    "ada_imle_nn_z = torch.randn(n, zdim)\n",
    "# ada_imle_nn_z = nn.functional.normalize(ada_imle_nn_z, dim=1)\n",
    "\n",
    "dists = torch.tensor([0.1] * n)\n",
    "prev = dists[:]\n",
    "distance_threshold = 1e-3\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    with torch.no_grad():\n",
    "#         if(e % 10000 == 0 and e > 0 and distance_threshold < 6e-3):\n",
    "#             distance_threshold += 1e-3\n",
    "#             print(\"Distance threshold is: \",distance_threshold)\n",
    "        dists = torch.sum((ada_imle_g(ada_imle_nn_z) - data_points)**2, dim=1)\n",
    "        to_update = dists < prev * tau \n",
    "\n",
    "        zs = torch.randn(nz, zdim)\n",
    "#         zs = nn.functional.normalize(zs, dim=1)\n",
    "\n",
    "        generated = ada_imle_g(zs).detach()\n",
    "        if e % plot_staleness == 0:\n",
    "            nns = torch.tensor(find_nn_improved(data_points[to_update], generated, limit=distance_threshold, print_results=True), dtype=torch.long)\n",
    "        else:\n",
    "            nns = torch.tensor(find_nn_improved(data_points[to_update], generated, limit=distance_threshold), dtype=torch.long)\n",
    "        ada_imle_nn_z[to_update] = zs[nns] + torch.randn(nns.shape[0], zdim) * noise_coef\n",
    "\n",
    "        generated = ada_imle_g(ada_imle_nn_z)\n",
    "        dists = torch.sum((generated - data_points)**2, dim=1)\n",
    "        prev[to_update] = dists[to_update] * tau\n",
    "#         if e % plot_staleness == 0:\n",
    "#             nz_fake = data_points.shape[0]*10\n",
    "#             zs_fake = torch.randn(nz_fake, zdim)\n",
    "#             plot_nns(ada_imle_g, data_points, zs_fake, ada_imle_nn_z, title=f\"Epoch {e}\", f_name=f\"plots_soviet/ada-improved-epoch-{e}.png\", arrow=False)\n",
    "\n",
    "\n",
    "    optim.zero_grad()\n",
    "    outs = ada_imle_g(ada_imle_nn_z)\n",
    "    dists = torch.sum((outs - data_points)**2, dim=0)\n",
    "\n",
    "    loss = dists.mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "#Saving the training visualizations as GIF\n",
    "# with imageio.get_writer(f'plots_soviet/adaptive_imle_improved_training.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,plot_staleness):\n",
    "#         filename = f\"plots_soviet/ada-improved-epoch-{e}.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         #os.remove(filename)\n",
    "\n",
    "# with imageio.get_writer(f'adaptive_imle_training_kde.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,staleness):\n",
    "#         filename = f\"plots/ada-epoch-{e}_kde.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         os.remove(filename)\n",
    "\n",
    "# zs = torch.randn(nz, zdim)\n",
    "# # zs = nn.functional.normalize(zs, dim=1)\n",
    "\n",
    "# plot_final(ada_imle_g, data_points, zs, None, title=\"Ada-IMLE new distance\", f_name=f\"plots_soviet/ada-improved-final.png\", arrow=False, vanilla=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num real: 150 Num fake: 150\n",
      "{'precision': 0.8133333333333334, 'recall': 0.9066666666666666, 'density': 0.9293333333333333, 'coverage': 0.9266666666666666}\n"
     ]
    }
   ],
   "source": [
    "nz_fake = data_points.shape[0]*1\n",
    "zs_fake = torch.randn(nz_fake, zdim)\n",
    "fake = ada_imle_g(zs_fake).cpu().detach().numpy()\n",
    "metrics = compute_prdc(real_features=data_points,\n",
    "                       fake_features=fake,\n",
    "                       nearest_k=5)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:59<00:00, 337.02it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 20000\n",
    "var_staleness = 200\n",
    "ada_imle_g_var = copy.deepcopy(g)\n",
    "optim = torch.optim.Adam(ada_imle_g_var.parameters(), lr=lr)\n",
    "nz = data_points.shape[0]*10\n",
    "ada_imle_nn_z = torch.randn(n, zdim)\n",
    "dists = torch.tensor([0.1] * n)\n",
    "prev = dists[:]\n",
    "nz_temp = nz\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dists = torch.sum((ada_imle_g_var(ada_imle_nn_z) - data_points)**2, dim=1)\n",
    "        to_update = dists < prev * tau \n",
    "\n",
    "        zs = torch.randn(nz_temp, zdim)\n",
    "        generated = ada_imle_g_var(zs).detach()\n",
    "        nns = torch.tensor([find_nn(d, generated) for d in data_points[to_update]], dtype=torch.long)\n",
    "        ada_imle_nn_z[to_update] = zs[nns] + torch.randn(nns.shape[0], zdim) * noise_coef\n",
    "\n",
    "        generated = ada_imle_g_var(ada_imle_nn_z)\n",
    "        dists = torch.sum((generated - data_points)**2, dim=1)\n",
    "        prev[to_update] = dists[to_update] * tau\n",
    "        # save data as tensor\n",
    "        torch.save(ada_imle_nn_z, f\"data/z-epoch-{e}.pt\")\n",
    "        torch.save(ada_imle_g_var, f\"data/g-epoch-{e}.pt\")\n",
    "        torch.save(data_points, f\"data/data_points.pt\")\n",
    "        torch.save(prev, f\"data/prev-epoch-{e}.pt\")\n",
    "        percentage_completed = e/epochs\n",
    "        if e % staleness == 0:\n",
    "            zs_fake = torch.randn(nz, zdim)\n",
    "            plot_nns(ada_imle_g_var, data_points, zs_fake, ada_imle_nn_z, title=f\"Epoch {e}\", f_name=f\"plots_soviet/ada-var-epoch-{e}.png\", arrow=False)\n",
    "        if e % var_staleness == 0:\n",
    "            nz_temp = nz\n",
    "        if (percentage_completed >= 0.85):\n",
    "            nz_temp = nz\n",
    "        if (percentage_completed < 0.85 and e % 5 == 0 and nz_temp > data_points.shape[0]):\n",
    "            nz_temp -= data_points.shape[0]\n",
    "        \n",
    "\n",
    "    optim.zero_grad()\n",
    "    outs = ada_imle_g_var(ada_imle_nn_z)\n",
    "    dists = torch.sum((outs - data_points)**2, dim=0)\n",
    "\n",
    "    loss = dists.mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "#Saving the training visualizations as GIF\n",
    "with imageio.get_writer(f'plots_soviet/adaptive_imle_var_training.gif', mode='I') as writer:\n",
    "    for e in range(0,epochs,staleness):\n",
    "        filename = f\"plots_soviet/ada-var-epoch-{e}.png\"\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        #os.remove(filename)\n",
    "\n",
    "        \n",
    "zs = torch.randn(nz, zdim)\n",
    "plot_nns(ada_imle_g_var, data_points, zs, None, title=\"Ada-IMLE variable\", f_name=f\"plots_soviet/ada-var-final.png\", arrow=False, vanilla=True)\n",
    "\n",
    "# with imageio.get_writer(f'adaptive_imle_training_kde.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,staleness):\n",
    "#         filename = f\"plots/ada-epoch-{e}_kde.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # you can ignore this part\n",
    "# # just plotting kde\n",
    "\n",
    "# interval = 10\n",
    "# to_save = list(range(0, epochs, interval)) + [epochs - 1]\n",
    "# print(to_save)\n",
    "# for e in to_save:\n",
    "#     zs = torch.load(f\"data/z-epoch-{e}.pt\")\n",
    "#     gs = torch.load(f\"data/g-epoch-{e}.pt\")\n",
    "#     data_points = torch.load(f\"data/data_points.pt\")\n",
    "#     plot_kde(gs(zs).detach(), data_points, f\"plots/epoch-{e}_kde.png\", f\"Epoch {e}\")\n",
    "\n",
    "# with imageio.get_writer(f'adaptive_imle_training_kde.gif', mode='I') as writer:\n",
    "#     # every 10\n",
    "#     for e in range(0, epochs, 10):\n",
    "#         filename = f\"plots/epoch-{e}_kde.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         writer.append_data(image)\n",
    "#     for i in range(10):\n",
    "#         filename = f\"plots/epoch-{epochs - 1}_kde.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # you can ignore this part\n",
    "# # just ploting the neighbourhood shrinking process\n",
    "\n",
    "# from utils import circles\n",
    "# from numpy import arange\n",
    "# def plot_with_circles(g, data_points, zs, prev, title=None, f_name=None, arrow=False):\n",
    "#     plt.clf()\n",
    "#     generated = g(zs).detach()\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     # plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "#     plt.scatter(data_points[:, 0], data_points[:, 1], label=\"Real data points\", color=\"blue\")\n",
    "#     plt.scatter(generated[:, 0], generated[:, 1], label=\"Nearest neighbours\", color=\"red\")\n",
    "#     radius = np.sqrt(prev)\n",
    "#     # outer_radius = np.sqrt(prev / tau)\n",
    "#     outer_radius = radius / tau\n",
    "#     # circles(data_points[:, 0], data_points[:, 1], radius, color=\"green\", alpha=0.1)\n",
    "#     for i in range(len(data_points)):\n",
    "#         circles(data_points[i, 0], data_points[i, 1], radius[i], color=\"green\", alpha=0.1)\n",
    "#         circles(data_points[i, 0], data_points[i, 1], outer_radius[i], color=\"green\", alpha=0.05, ec='black')\n",
    "#     if arrow:\n",
    "#         gen_to_data_vec = data_points - generated\n",
    "#         # unit_vecs = gen_to_data_vec / np.linalg.norm(gen_to_data_vec, axis=1)[:, None]\n",
    "#         plt.quiver(generated[:, 0], generated[:, 1], 0.19*gen_to_data_vec[:, 0], 0.19*gen_to_data_vec[:, 1], alpha=0.5,\n",
    "#                    color=\"black\", scale_units=\"xy\", angles='xy', scale=0.2, width=0.0015, headwidth=10, headlength=10, label=\"Nearest neighbour vectors\")\n",
    "\n",
    "#     plt.legend()\n",
    "#     plt.title(title)\n",
    "#     plt.ylim(-0.3, 0.4)\n",
    "#     plt.xlim(-0.35, 0.35)\n",
    "#     plt.savefig(f_name)\n",
    "#     plt.close()\n",
    "\n",
    "# interval = 10\n",
    "# to_save = list(range(0, epochs, interval)) + [epochs - 1]\n",
    "# prev_0 = torch.load(f\"data/prev-epoch-0.pt\")\n",
    "# for e in to_save:\n",
    "#     zs = torch.load(f\"data/z-epoch-{e}.pt\")\n",
    "#     gs = torch.load(f\"data/g-epoch-{e}.pt\")\n",
    "#     data_points = torch.load(f\"data/data_points.pt\")\n",
    "#     prev = torch.load(f\"data/prev-epoch-{e}.pt\")\n",
    "#     # prev = torch.min(prev, prev_0)\n",
    "#     plot_with_circles(gs, data_points, zs, prev, title=f\"Epoch {e}\", f_name=f\"plots2/epoch-{e}.png\", arrow=True)\n",
    "#     plot_kde(gs(zs).detach(), data_points, f\"plots/epoch-{e}_kde.png\", f\"Epoch {e}\")\n",
    "\n",
    "# # save gif\n",
    "# with imageio.get_writer(f'adaptive_imle_training.gif', mode='I') as writer:\n",
    "#     for e in range(0, epochs, interval):\n",
    "#         filename = f\"plots2/epoch-{e}.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#     filename = f\"plots2/epoch-299.png\"\n",
    "#     image = imageio.imread(filename)\n",
    "#     for i in range(20):\n",
    "#         writer.append_data(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla IMLE implementation\n",
    "Here we implement a basic version of Vanilla IMLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100000/100000 [00:55<00:00, 1800.39it/s]\n"
     ]
    }
   ],
   "source": [
    "imle_g = copy.deepcopy(g)\n",
    "optim = torch.optim.Adam(imle_g.parameters(), lr=lr)\n",
    "imle_nn_z = torch.randn(n, zdim)\n",
    "epochs = 100000\n",
    "staleness = 50\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    with torch.no_grad():\n",
    "        if e % staleness == 0:\n",
    "            zs = torch.randn(nz, zdim)\n",
    "            generated = imle_g(zs).detach()\n",
    "            nns = torch.tensor([find_nn_new(d, generated) for d in data_points], dtype=torch.long)\n",
    "            imle_nn_z = zs[nns] + torch.randn(nns.shape[0], zdim) * noise_coef\n",
    "#         if e % plot_staleness == 0:\n",
    "#             plot_nns(imle_g, data_points, zs, imle_nn_z, title=f\"Epoch {e}\", f_name=f\"plots_soviet/epoch-{e}.png\", arrow=False)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    outs = imle_g(imle_nn_z)\n",
    "    dists = torch.sum((outs - data_points)**2, dim=1)\n",
    "    loss = dists.mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "# Saving the training visualizations as GIF\n",
    "# with imageio.get_writer(f'plots_soviet/imle_training.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,plot_staleness):\n",
    "#         filename = f\"plots_soviet/epoch-{e}.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         #os.remove(filename)\n",
    "        \n",
    "\n",
    "# zs = torch.randn(nz, zdim)\n",
    "# plot_nns(imle_g, data_points, zs, None, title=\"Vanilla IMLE new distance\", f_name=f\"plots_soviet/imle-final.png\", arrow=False, vanilla=True)\n",
    "\n",
    "\n",
    "# with imageio.get_writer(f'imle_training_kde.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,staleness):\n",
    "#         filename = f\"plots/epoch-{e}_kde.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num real: 150 Num fake: 150\n",
      "{'precision': 0.9733333333333334, 'recall': 0.9133333333333333, 'density': 1.4186666666666667, 'coverage': 1.0}\n"
     ]
    }
   ],
   "source": [
    "nz_fake = data_points.shape[0]*1\n",
    "zs_fake = torch.randn(nz_fake, zdim)\n",
    "fake = imle_g(zs_fake).cpu().detach().numpy()\n",
    "metrics = compute_prdc(real_features=data_points,\n",
    "                       fake_features=fake,\n",
    "                       nearest_k=5)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:39<00:00, 1276.54it/s]\n"
     ]
    }
   ],
   "source": [
    "imle_g = copy.deepcopy(g)\n",
    "optim = torch.optim.Adam(imle_g.parameters(), lr=lr)\n",
    "imle_nn_z = torch.randn(n, zdim)\n",
    "epochs = 50000\n",
    "staleness = 50\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    with torch.no_grad():\n",
    "        if e % staleness == 0:\n",
    "            zs = torch.randn(nz, zdim)\n",
    "            generated = imle_g(zs).detach()\n",
    "            nns = torch.tensor([find_nn_new(d, generated) for d in data_points], dtype=torch.long)\n",
    "            imle_nn_z = zs[nns] + torch.randn(nns.shape[0], zdim) * noise_coef\n",
    "#         if e % plot_staleness == 0:\n",
    "#             plot_nns(imle_g, data_points, zs, imle_nn_z, title=f\"Epoch {e}\", f_name=f\"plots_soviet/epoch-{e}.png\", arrow=False)\n",
    "\n",
    "    norms = torch.norm(imle_nn_z,dim=1,p=2)\n",
    "    norm_imle_nn_z = nn.functional.normalize(imle_nn_z, dim=1, p=2)\n",
    "    \n",
    "    b = torch.normal(0,1,size=norm_imle_nn_z.shape)\n",
    "    b = nn.functional.normalize(b, dim=1)\n",
    "\n",
    "    w = b - torch.unsqueeze(torch.einsum('ij,ij->i',b,norm_imle_nn_z),-1) * norm_imle_nn_z\n",
    "    w = nn.functional.normalize(w,p=2,dim=-1)\n",
    "\n",
    "    cur_batch_latents = torch.cos(angle_distort) * norm_imle_nn_z + torch.sin(angle_distort) * w\n",
    "    cur_batch_latents = cur_batch_latents * norms.view(-1, 1)\n",
    "   \n",
    "    optim.zero_grad()\n",
    "    outs = imle_g(cur_batch_latents)\n",
    "    dists = torch.sum((outs - data_points)**2, dim=1)\n",
    "    loss = dists.mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "# Saving the training visualizations as GIF\n",
    "# with imageio.get_writer(f'plots_soviet/imle_training.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,plot_staleness):\n",
    "#         filename = f\"plots_soviet/epoch-{e}.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         #os.remove(filename)\n",
    "        \n",
    "\n",
    "# zs = torch.randn(nz, zdim)\n",
    "# plot_nns(imle_g, data_points, zs, None, title=\"Vanilla IMLE new distance\", f_name=f\"plots_soviet/imle-final.png\", arrow=False, vanilla=True)\n",
    "\n",
    "\n",
    "# with imageio.get_writer(f'imle_training_kde.gif', mode='I') as writer:\n",
    "#     for e in range(0,epochs,staleness):\n",
    "#         filename = f\"plots/epoch-{e}_kde.png\"\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "#         os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num real: 150 Num fake: 1500\n",
      "{'precision': 0.9993333333333333, 'recall': 0.72, 'density': 2.1448, 'coverage': 1.0}\n"
     ]
    }
   ],
   "source": [
    "nz_fake = data_points.shape[0]*10\n",
    "zs_fake = torch.randn(nz_fake, zdim)\n",
    "fake = imle_g(zs_fake).cpu().detach().numpy()\n",
    "metrics = compute_prdc(real_features=data_points,\n",
    "                       fake_features=fake,\n",
    "                       nearest_k=5)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results\n",
    "Here we visualize nearest neighbour of each data example among randomly generated samples after training. We can see that Vanilla IMLE fails to cover the left-most and right-most data examples while Adaptive IMLE succeeds in covering all data examples the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 500  # number of generated samples\n",
    "\n",
    "zs = torch.randn(nz, zdim)\n",
    "generated = ada_imle_g(zs).detach()\n",
    "nns = [find_nn(data_points[i], generated) for i in range(n)]\n",
    "plot_nns(ada_imle_g, data_points, zs[nns], title=f\"Adaptive IMLE results\", arrow=True)\n",
    "\n",
    "generated = imle_g(zs).detach()\n",
    "nns = [find_nn(data_points[i], generated) for i in range(n)]\n",
    "plot_nns(imle_g, data_points, zs[nns], title=f\"IMLE results\", arrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated = generated.detach().numpy()\n",
    "# sns.kdeplot(data={'x': generated[:, 0], 'y': generated[:, 1]}, x=\"x\", y=\"y\", fill=True, alpha=1., cmap='rocket_r', levels=30) \n",
    "generated = imle_g(zs).detach().numpy()\n",
    "data = pd.DataFrame.from_dict({'x': generated[:, 0], 'y': generated[:, 1]})\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.ylim(-0.3, 0.4)\n",
    "plt.xlim(-0.35, 0.35)\n",
    "plt.scatter(data_points[:, 0], data_points[:, 1], label=\"Real data points\", color=\"blue\")\n",
    "sns.kdeplot(data=data, fill=True, alpha=1., palette='rocket_r', levels=30, multiple=\"fill\") \n",
    "plot_nns(imle_g, data_points, zs, title=f\"IMLE results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = ada_imle_g(zs).detach().numpy()\n",
    "data = pd.DataFrame.from_dict({'x': generated[:, 0], 'y': generated[:, 1]})\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.ylim(-0.3, 0.4)\n",
    "plt.xlim(-0.35, 0.35)\n",
    "plt.scatter(data_points[:, 0], data_points[:, 1], label=\"Real data points\", color=\"blue\")\n",
    "sns.kdeplot(data=data, fill=True, alpha=1.0, palette='rocket_r', levels=30) \n",
    "plot_nns(ada_imle_g, data_points, zs, title=f\"IMLE results\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
